{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Any, Set, Tuple, List, FrozenSet, Dict\n",
    "from functools import lru_cache\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "import statistics\n",
    "\n",
    "# --- SBERT Helpers ---\n",
    "sbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "_seen_debugs = {\n",
    "    level: set() for level in [\n",
    "        \"literal_flat\", \"literal_weighted\",\n",
    "        \"clause_flat\", \"clause_weighted\",\n",
    "        \"formula\"]\n",
    "}\n",
    "_debug_summary = {\n",
    "    level: [] for level in [\n",
    "        \"literal_flat\", \"literal_weighted\",\n",
    "        \"clause_flat\", \"clause_weighted\",\n",
    "        \"formula\"]\n",
    "}\n",
    "\n",
    "@lru_cache(maxsize=2048)\n",
    "def get_embedding(text: str):\n",
    "    return sbert_model.encode(text, convert_to_tensor=True)\n",
    "\n",
    "def normalize_str(s: str) -> str:\n",
    "    return s.lower().replace(\"_\", \" \").replace(\"(\", \"\").replace(\")\", \"\").replace(\"not \", \"¬\").strip()\n",
    "\n",
    "def sim_sbert_normalized(a: str, b: str) -> float:\n",
    "    a_norm, b_norm = normalize_str(a), normalize_str(b)\n",
    "    return util.cos_sim(get_embedding(a_norm), get_embedding(b_norm)).item()\n",
    "\n",
    "def agg_max(scores: List[float]) -> float:\n",
    "    return max(scores) if scores else 0.0\n",
    "\n",
    "def agg_avg(scores: List[float]) -> float:\n",
    "    return sum(scores) / len(scores) if scores else 0.0\n",
    "\n",
    "def agg_softmax(scores: List[float], temperature: float = 2.5) -> float:\n",
    "    if not scores:\n",
    "        return 0.0\n",
    "    exp_scores = [np.exp(s * temperature) for s in scores]\n",
    "    softmax_weights = [e / sum(exp_scores) for e in exp_scores]\n",
    "    return sum(w * s for w, s in zip(softmax_weights, scores))\n",
    "\n",
    "def pointwise_similarity_weighted(\n",
    "    args1: List[str],\n",
    "    args2: List[str],\n",
    "    simC: Callable[[str, str], float],\n",
    "    weights1: Dict[str, float],\n",
    "    weights2: Dict[str, float],\n",
    "    positional_weight: float = 0.8,\n",
    "    unordered_weight: float = 0.2,\n",
    "    diff: float = 0\n",
    ") -> float:\n",
    "    if not args1 or not args2:\n",
    "        return 0.0\n",
    "\n",
    "    min_len = min(len(args1), len(args2))\n",
    "    sim_pos, total_weight_pos = 0.0, 0.0\n",
    "    for i in range(min_len):\n",
    "        a1, a2 = args1[i], args2[i]\n",
    "        sim = simC(a1, a2)\n",
    "        w1 = weights1.get(a1, 0.0)\n",
    "        w2 = weights2.get(a2, 0.0)\n",
    "        importance = w1 * w2\n",
    "        sim_pos += importance * sim\n",
    "        total_weight_pos += importance\n",
    "    sim_pos = sim_pos / (total_weight_pos + diff) if total_weight_pos > 0 else 0.0\n",
    "\n",
    "    sim_unordered, total_weight_unordered = 0.0, 0.0\n",
    "    for a1 in args1:\n",
    "        w1 = weights1.get(a1, 0.0)\n",
    "        best_sim, best_imp = 0.0, 0.0\n",
    "        for a2 in args2:\n",
    "            w2 = weights2.get(a2, 0.0)\n",
    "            sim = simC(a1, a2)\n",
    "            importance = w1 * w2\n",
    "            if sim > best_sim:\n",
    "                best_sim, best_imp = sim, importance\n",
    "        sim_unordered += best_sim * best_imp\n",
    "        total_weight_unordered += best_imp\n",
    "\n",
    "    sim_unordered = sim_unordered / (total_weight_unordered + diff) if total_weight_unordered > 0 else 0.0\n",
    "\n",
    "    return positional_weight * sim_pos + unordered_weight * sim_unordered\n",
    "\n",
    "def safe_sort_clause(c: FrozenSet[Tuple[str, Tuple[str, ...]]]) -> List:\n",
    "    return sorted(list(c), key=lambda lit: (lit[0], lit[1]))\n",
    "\n",
    "def record_debug(level: str, key: frozenset, entry: Tuple):\n",
    "    if key not in _seen_debugs[level]:\n",
    "        _seen_debugs[level].add(key)\n",
    "        _debug_summary[level].append(entry)\n",
    "\n",
    "def simLiteral_flat(\n",
    "    obj1: Tuple[str, Tuple[str, ...]],\n",
    "    obj2: Tuple[str, Tuple[str, ...]],\n",
    "    debug: dict = None,\n",
    "    diff: float = 0.0\n",
    ") -> float:\n",
    "    pred1, args1 = obj1\n",
    "    pred2, args2 = obj2\n",
    "\n",
    "    sim_pred = sim_sbert_normalized(pred1, pred2)\n",
    "    sim_args = pointwise_similarity_weighted(\n",
    "        list(args1), list(args2), sim_sbert_normalized,\n",
    "        weights1={k: 1.0 for k in args1},\n",
    "        weights2={k: 1.0 for k in args2},\n",
    "        diff=diff\n",
    "    )\n",
    "\n",
    "    score = 0.5 * sim_pred + 0.5 * sim_args\n",
    "\n",
    "    if debug and debug.get(\"literal\", False):\n",
    "        key = frozenset({obj1, obj2})\n",
    "        canonical = tuple(sorted([obj1, obj2]))\n",
    "        record_debug(\"literal_flat\", key, (*canonical, sim_pred, sim_args, score))\n",
    "\n",
    "    return score\n",
    "\n",
    "def simLiteral(\n",
    "    obj1: Tuple[str, Tuple[str, ...]],\n",
    "    obj2: Tuple[str, Tuple[str, ...]],\n",
    "    predicate_weights: Dict[str, float],\n",
    "    constant_weights: Dict[str, float],\n",
    "    debug: dict = None,\n",
    "    diff: float = 0.0\n",
    ") -> float:\n",
    "    pred1, args1 = obj1\n",
    "    pred2, args2 = obj2\n",
    "\n",
    "    sim_pred = sim_sbert_normalized(pred1, pred2)\n",
    "    imp_pred = predicate_weights.get(pred1, 0.0) * predicate_weights.get(pred2, 0.0)\n",
    "    num = sim_pred * imp_pred\n",
    "    denom = imp_pred\n",
    "\n",
    "    sim_args = pointwise_similarity_weighted(\n",
    "        list(args1), list(args2), sim_sbert_normalized,\n",
    "        weights1=constant_weights,\n",
    "        weights2=constant_weights,\n",
    "        diff=diff\n",
    "    )\n",
    "\n",
    "    imp_args_total = sum(\n",
    "        constant_weights.get(a1, 0.0) * constant_weights.get(a2, 0.0)\n",
    "        for a1 in args1 for a2 in args2\n",
    "    )\n",
    "    num += sim_args * imp_args_total\n",
    "    denom += imp_args_total\n",
    "\n",
    "    score = num / (denom + diff) if denom > 0 else 0.0\n",
    "\n",
    "    if debug and debug.get(\"literal\", False):\n",
    "        key = frozenset({obj1, obj2})\n",
    "        canonical = tuple(sorted([obj1, obj2]))\n",
    "        record_debug(\"literal_weighted\", key, (*canonical, sim_pred, sim_args, score))\n",
    "\n",
    "    return score\n",
    "\n",
    "def generalized_tversky_similarity(\n",
    "    X: Set[Any],\n",
    "    Y: Set[Any],\n",
    "    sim: Callable[[Any, Any], float],\n",
    "    alpha: float = 1.0,\n",
    "    beta: float = 1.0,\n",
    "    p: float = 1.0,\n",
    "    agg: Callable[[List[float]], float] = max,\n",
    "    debug: dict = None,\n",
    "    debug_level: str = \"\"\n",
    ") -> float:\n",
    "    if not X or not Y:\n",
    "        return 0.0\n",
    "\n",
    "    def membership(x, Y):\n",
    "        return agg([sim(x, y) ** p for y in Y])\n",
    "\n",
    "    match_X = [membership(x, Y) for x in X]\n",
    "    match_Y = [membership(y, X) for y in Y]\n",
    "\n",
    "    a = (sum(match_X) + sum(match_Y)) / 2\n",
    "    b = sum(1 - s for s in match_X)\n",
    "    c = sum(1 - s for s in match_Y)\n",
    "\n",
    "    denom = a + alpha * b + beta * c\n",
    "    score = a / denom if denom > 0 else 0.0\n",
    "\n",
    "    if debug and debug.get(debug_level, False):\n",
    "        _debug_summary[debug_level].append((\"TOTAL\", a, b, c, score))\n",
    "        seen = set()\n",
    "        for x in X:\n",
    "            for y in Y:\n",
    "                key = frozenset([x, y])\n",
    "                if key not in seen:\n",
    "                    seen.add(key)\n",
    "                    s = sim(x, y)\n",
    "                    _debug_summary[debug_level].append((\"clause_pair\", x, y, s))  # ✓ Ajouter la similarité ici\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def simFormulaSet(\n",
    "    F1: Set[FrozenSet[Tuple[str, Tuple[str, ...]]]],\n",
    "    F2: Set[FrozenSet[Tuple[str, Tuple[str, ...]]]],\n",
    "    clause_weights1: Dict[FrozenSet[Tuple[str, Tuple[str, ...]]], float],\n",
    "    clause_weights2: Dict[FrozenSet[Tuple[str, Tuple[str, ...]]], float],\n",
    "    predicate_weights1: Dict[str, float],\n",
    "    predicate_weights2: Dict[str, float],\n",
    "    constant_weights1: Dict[str, float],\n",
    "    constant_weights2: Dict[str, float],\n",
    "    params: dict = None,\n",
    "    debug: dict = None\n",
    ") -> Tuple[float, Dict[str, List[Any]]]:\n",
    "    for level in _seen_debugs:\n",
    "        _seen_debugs[level].clear()\n",
    "    for level in _debug_summary:\n",
    "        _debug_summary[level].clear()\n",
    "\n",
    "    predicate_weights = {**predicate_weights1, **predicate_weights2}\n",
    "    constant_weights = {**constant_weights1, **constant_weights2}\n",
    "\n",
    "    sum_preds = sum(predicate_weights1.values()) + sum(predicate_weights2.values())\n",
    "    sum_consts = sum(constant_weights1.values()) + sum(constant_weights2.values())\n",
    "    diff = 2 - sum_preds - sum_consts\n",
    "    epsilon = 1e-4\n",
    "    diff = 0.0 if abs(diff) < epsilon else diff\n",
    "\n",
    "    all_clauses1 = sorted(F1, key=safe_sort_clause)\n",
    "    all_clauses2 = sorted(F2, key=safe_sort_clause)\n",
    "\n",
    "    # --- Flat clause similarities ---\n",
    "    flat_similarities = {}\n",
    "    for c1 in all_clauses1:\n",
    "        for c2 in all_clauses2:\n",
    "            sim = generalized_tversky_similarity(\n",
    "                c1, c2,\n",
    "                sim=simLiteral_flat,\n",
    "                alpha=1.0, beta=1.0, p=1.0, agg=max,\n",
    "                debug=debug,\n",
    "                debug_level=\"clause_flat\"\n",
    "            )\n",
    "            _debug_summary[\"clause_flat\"].append((\"clause_pair_score\", c1, c2, sim))\n",
    "            flat_similarities[(c1, c2)] = sim\n",
    "\n",
    "    # --- Best clause matches ---\n",
    "    best_matches = {}\n",
    "    for c1 in all_clauses1:\n",
    "        best_c2 = max(all_clauses2, key=lambda c2: flat_similarities[(c1, c2)])\n",
    "        best_matches[(c1, best_c2)] = flat_similarities[(c1, best_c2)]\n",
    "    for c2 in all_clauses2:\n",
    "        best_c1 = max(all_clauses1, key=lambda c1: flat_similarities[(c1, c2)])\n",
    "        best_matches[(best_c1, c2)] = flat_similarities[(best_c1, c2)]\n",
    "\n",
    "    # --- Weighted clause similarities on best matches ---\n",
    "    weighted_scores = []\n",
    "    for (c1, c2), _ in best_matches.items():\n",
    "        sim = generalized_tversky_similarity(\n",
    "            c1, c2,\n",
    "            sim=lambda l1, l2: simLiteral(\n",
    "                l1, l2,\n",
    "                predicate_weights=predicate_weights,\n",
    "                constant_weights=constant_weights,\n",
    "                debug=debug,\n",
    "                diff=diff\n",
    "            ),\n",
    "            alpha=params.get(\"clause\", {}).get(\"alpha\", 0.5),\n",
    "            beta=params.get(\"clause\", {}).get(\"beta\", 0.5),\n",
    "            p=params.get(\"clause\", {}).get(\"p\", 1.0),\n",
    "            agg=params.get(\"clause\", {}).get(\"agg\", max),\n",
    "            debug=debug,\n",
    "            debug_level=\"clause_weighted\"\n",
    "        )\n",
    "        _debug_summary[\"clause_weighted\"].append((\"clause_pair_score\", c1, c2, sim))\n",
    "        w1 = clause_weights1.get(c1, 1.0)\n",
    "        w2 = clause_weights2.get(c2, 1.0)\n",
    "        weighted_scores.append((sim, (w1 + w2)/2))\n",
    "\n",
    "    # --- Final weighted score ---\n",
    "    total_weight = sum(w for _, w in weighted_scores)\n",
    "    #total_weight = sum(1 for _, w in weighted_scores)\n",
    "    #print(weighted_scores)\n",
    "    final_score = sum(s * w for s, w in weighted_scores) / total_weight if total_weight > 0 else 0.0\n",
    "\n",
    "    _debug_summary[\"formula\"].append((\"TOTAL\", 0, 0, 0, final_score))\n",
    "    _debug_summary[\"formula\"].extend([\n",
    "        (\"formula_pair\", c1, c2, flat_similarities[(c1, c2)])\n",
    "        for (c1, c2) in best_matches.keys()\n",
    "    ])\n",
    "\n",
    "    return final_score, _debug_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_debug_output(summary: dict, debug: dict = None, top_n: int = 10):\n",
    "    print(\"\\n🔍 SUMMARY OF SIMILARITY COMPARISON\\n\")\n",
    "\n",
    "    # 1. Literal FLAT\n",
    "    if debug.get(\"literal\", False):\n",
    "        literals = summary.get(\"literal_flat\", [])\n",
    "        print(\"📌 LITERAL LEVEL (Flat)\")\n",
    "        print(f\"  → Total literal pairs (flat): {len(literals)}\")\n",
    "        for (lit1, lit2, sim_pred, sim_args, score) in literals:\n",
    "            print(f\"    - {lit1} ⇄ {lit2}\")\n",
    "            print(f\"      • predicate similarity: {sim_pred:.3f}\")\n",
    "            print(f\"      • argument similarity : {sim_args:.3f}\")\n",
    "            print(f\"      • literal similarity   : {score:.3f}\")\n",
    "\n",
    "    # 2. Literal WEIGHTED\n",
    "    literals_w = summary.get(\"literal_weighted\", [])\n",
    "    if literals_w:\n",
    "        print(\"\\n📌 LITERAL LEVEL (Weighted)\")\n",
    "        print(f\"  → Total literal pairs (weighted): {len(literals_w)}\")\n",
    "        for (lit1, lit2, sim_pred, sim_args, score) in literals_w:\n",
    "            print(f\"    - {lit1} ⇄ {lit2}\")\n",
    "            print(f\"      • predicate similarity (weighted): {sim_pred:.3f}\")\n",
    "            print(f\"      • argument similarity  (weighted): {sim_args:.3f}\")\n",
    "            print(f\"      • literal similarity   (weighted): {score:.3f}\")\n",
    "\n",
    "    # 3. Clause FLAT\n",
    "    clauses = summary.get(\"clause_flat\", [])\n",
    "    if clauses:\n",
    "        print(\"\\n📌 CLAUSE LEVEL (Flat)\")\n",
    "        print(f\"  → Total clause pairs compared (flat): {len(clauses)}\")\n",
    "        for (_, clause1, clause2, score) in clauses:\n",
    "            print(f\"    - Clause 1: {clause1}\")\n",
    "            print(f\"      Clause 2: {clause2}\")\n",
    "            print(f\"      → Clause similarity: {score:.3f}\")\n",
    "\n",
    "    # 4. Clause WEIGHTED\n",
    "    clauses_w = summary.get(\"clause_weighted\", [])\n",
    "    if clauses_w:\n",
    "        print(\"\\n📌 CLAUSE LEVEL (Weighted)\")\n",
    "        print(f\"  → Total clause pairs (weighted best matches): {len(clauses_w)}\")\n",
    "        for (_, clause1, clause2, score) in clauses_w:\n",
    "            print(f\"    - Clause 1: {clause1}\")\n",
    "            print(f\"      Clause 2: {clause2}\")\n",
    "            print(f\"      → Weighted clause similarity: {score:.3f}\")\n",
    "\n",
    "    # 5. FORMULA\n",
    "    formulas = summary.get(\"formula\", [])\n",
    "    print(\"\\n📌 FORMULA LEVEL\")\n",
    "    totals = [e for e in formulas if isinstance(e, tuple) and e[0] == \"TOTAL\"]\n",
    "    for (_, a, b, c, score) in totals:\n",
    "        print(\"  → Final formula similarity score (weighted over best clause matches):\")\n",
    "        print(f\"      Score = {score:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔷 FINAL SIMILARITY SCORE: 0.623\n",
      "\n",
      "🔍 SUMMARY OF SIMILARITY COMPARISON\n",
      "\n",
      "📌 LITERAL LEVEL (Flat)\n",
      "  → Total literal pairs (flat): 0\n",
      "\n",
      "📌 LITERAL LEVEL (Weighted)\n",
      "  → Total literal pairs (weighted): 3\n",
      "    - ('AtLocation', ('Dog', 'Zoo')) ⇄ ('AtLocation', ('Dog', 'Zoo'))\n",
      "      • predicate similarity (weighted): 1.000\n",
      "      • argument similarity  (weighted): 1.000\n",
      "      • literal similarity   (weighted): 1.000\n",
      "    - ('AtLocation', ('Monkey', 'Zoo')) ⇄ ('AtLocation', ('Monkey', 'Zoo'))\n",
      "      • predicate similarity (weighted): 1.000\n",
      "      • argument similarity  (weighted): 1.000\n",
      "      • literal similarity   (weighted): 1.000\n",
      "    - ('Teasing', ('Dog', 'Monkey')) ⇄ ('Teasing', ('Monkey', 'Dog'))\n",
      "      • predicate similarity (weighted): 1.000\n",
      "      • argument similarity  (weighted): 0.573\n",
      "      • literal similarity   (weighted): 0.581\n",
      "\n",
      "📌 CLAUSE LEVEL (Flat)\n",
      "  → Total clause pairs compared (flat): 9\n",
      "    - Clause 1: frozenset({('AtLocation', ('Dog', 'Zoo'))})\n",
      "      Clause 2: frozenset({('AtLocation', ('Dog', 'Zoo'))})\n",
      "      → Clause similarity: 1.000\n",
      "    - Clause 1: frozenset({('AtLocation', ('Dog', 'Zoo'))})\n",
      "      Clause 2: frozenset({('AtLocation', ('Monkey', 'Zoo'))})\n",
      "      → Clause similarity: 0.766\n",
      "    - Clause 1: frozenset({('AtLocation', ('Dog', 'Zoo'))})\n",
      "      Clause 2: frozenset({('Teasing', ('Monkey', 'Dog'))})\n",
      "      → Clause similarity: 0.186\n",
      "    - Clause 1: frozenset({('AtLocation', ('Monkey', 'Zoo'))})\n",
      "      Clause 2: frozenset({('AtLocation', ('Dog', 'Zoo'))})\n",
      "      → Clause similarity: 0.766\n",
      "    - Clause 1: frozenset({('AtLocation', ('Monkey', 'Zoo'))})\n",
      "      Clause 2: frozenset({('AtLocation', ('Monkey', 'Zoo'))})\n",
      "      → Clause similarity: 1.000\n",
      "    - Clause 1: frozenset({('AtLocation', ('Monkey', 'Zoo'))})\n",
      "      Clause 2: frozenset({('Teasing', ('Monkey', 'Dog'))})\n",
      "      → Clause similarity: 0.266\n",
      "    - Clause 1: frozenset({('Teasing', ('Dog', 'Monkey'))})\n",
      "      Clause 2: frozenset({('AtLocation', ('Dog', 'Zoo'))})\n",
      "      → Clause similarity: 0.291\n",
      "    - Clause 1: frozenset({('Teasing', ('Dog', 'Monkey'))})\n",
      "      Clause 2: frozenset({('AtLocation', ('Monkey', 'Zoo'))})\n",
      "      → Clause similarity: 0.207\n",
      "    - Clause 1: frozenset({('Teasing', ('Dog', 'Monkey'))})\n",
      "      Clause 2: frozenset({('Teasing', ('Monkey', 'Dog'))})\n",
      "      → Clause similarity: 0.648\n",
      "\n",
      "📌 CLAUSE LEVEL (Weighted)\n",
      "  → Total clause pairs (weighted best matches): 3\n",
      "    - Clause 1: frozenset({('AtLocation', ('Dog', 'Zoo'))})\n",
      "      Clause 2: frozenset({('AtLocation', ('Dog', 'Zoo'))})\n",
      "      → Weighted clause similarity: 1.000\n",
      "    - Clause 1: frozenset({('AtLocation', ('Monkey', 'Zoo'))})\n",
      "      Clause 2: frozenset({('AtLocation', ('Monkey', 'Zoo'))})\n",
      "      → Weighted clause similarity: 1.000\n",
      "    - Clause 1: frozenset({('Teasing', ('Dog', 'Monkey'))})\n",
      "      Clause 2: frozenset({('Teasing', ('Monkey', 'Dog'))})\n",
      "      → Weighted clause similarity: 0.581\n",
      "\n",
      "📌 FORMULA LEVEL\n",
      "  → Final formula similarity score (weighted over best clause matches):\n",
      "      Score = 0.623\n"
     ]
    }
   ],
   "source": [
    "# --- Données pondérées pour I_SA et I_SB ---\n",
    "weighted_T1 = {\n",
    "    \"instances\": frozenset({\n",
    "        frozenset({(\"Teasing\", (\"Dog\", \"Monkey\"))}),\n",
    "        frozenset({(\"AtLocation\", (\"Dog\", \"Zoo\"))}),\n",
    "        frozenset({(\"AtLocation\", (\"Monkey\", \"Zoo\"))}),\n",
    "    }),\n",
    "    \"clause_weights\": {\n",
    "        frozenset({(\"Teasing\", (\"Dog\", \"Monkey\"))}): 0.9,\n",
    "        frozenset({(\"AtLocation\", (\"Dog\", \"Zoo\"))}): 0.05,\n",
    "        frozenset({(\"AtLocation\", (\"Monkey\", \"Zoo\"))}): 0.05,\n",
    "    },\n",
    "    \"predicate_weights\": {\n",
    "        \"Teasing\": 0.1,\n",
    "        \"AtLocation\": 0.1,\n",
    "    },\n",
    "    \"constant_weights\": {\n",
    "        \"Dog\": 0.35,\n",
    "        \"Monkey\": 0.35,\n",
    "        \"Zoo\": 0.1\n",
    "    }\n",
    "}\n",
    "\n",
    "weighted_T2 = {\n",
    "    \"instances\": frozenset({\n",
    "        frozenset({(\"Teasing\", (\"Monkey\", \"Dog\"))}),\n",
    "        frozenset({(\"AtLocation\", (\"Dog\", \"Zoo\"))}),\n",
    "        frozenset({(\"AtLocation\", (\"Monkey\", \"Zoo\"))}),\n",
    "    }),\n",
    "    \"clause_weights\": {\n",
    "        frozenset({(\"Teasing\", (\"Monkey\", \"Dog\"))}): 0.9,\n",
    "        frozenset({(\"AtLocation\", (\"Dog\", \"Zoo\"))}): 0.05,\n",
    "        frozenset({(\"AtLocation\", (\"Monkey\", \"Zoo\"))}): 0.05,\n",
    "    },\n",
    "    \"predicate_weights\": {\n",
    "        \"Teasing\": 0.1,\n",
    "        \"AtLocation\": 0.1,\n",
    "    },\n",
    "    \"constant_weights\": {\n",
    "        \"Dog\": 0.35,\n",
    "        \"Monkey\": 0.35,\n",
    "        \"Zoo\": 0.1\n",
    "    }\n",
    "}\n",
    "\n",
    "# --- Paramètres de similarité ---\n",
    "params = {\n",
    "    \"clause\": {\n",
    "        \"alpha\": 0.5,\n",
    "        \"beta\": 0.5,\n",
    "        \"p\": 1,\n",
    "        \"agg\": agg_softmax\n",
    "    },\n",
    "    \"formula\": {\n",
    "        \"alpha\": 0.5,\n",
    "        \"beta\": 0.5,\n",
    "        \"p\": 1,\n",
    "        \"agg\": agg_max\n",
    "    }\n",
    "}\n",
    "\n",
    "# --- Flags de debug ---\n",
    "debug_flags = {\n",
    "    \"literal\": True,\n",
    "    \"clause\": True,\n",
    "    \"formula\": True\n",
    "}\n",
    "\n",
    "# --- Appel de la fonction de similarité complète ---\n",
    "score, summary = simFormulaSet(\n",
    "    F1=weighted_T1[\"instances\"],\n",
    "    F2=weighted_T2[\"instances\"],\n",
    "    clause_weights1=weighted_T1[\"clause_weights\"],\n",
    "    clause_weights2=weighted_T2[\"clause_weights\"],\n",
    "    predicate_weights1=weighted_T1[\"predicate_weights\"],\n",
    "    predicate_weights2=weighted_T2[\"predicate_weights\"],\n",
    "    constant_weights1=weighted_T1[\"constant_weights\"],\n",
    "    constant_weights2=weighted_T2[\"constant_weights\"],\n",
    "    params=params,\n",
    "    debug=debug_flags\n",
    ")\n",
    "\n",
    "print(f\"\\n🔷 FINAL SIMILARITY SCORE: {score:.3f}\")\n",
    "# --- Affichage du résumé complet ---\n",
    "summarize_debug_output(summary, debug=debug_flags)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
